{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cis6930-week12-pytorch-lightning-demo-students.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRgpqL0KVO43"
      },
      "source": [
        "# CIS6930 Week 12: Pytorch Lightning Quick Start\n",
        "\n",
        "---\n",
        "\n",
        "Preparation: Go to `Runtime > Change runtime type` and choose `GPU` for the hardware accelerator.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MMZ5mxJ2iUy"
      },
      "source": [
        "gpu_info = !nvidia-smi -L\n",
        "gpu_info = \"\\n\".join(gpu_info)\n",
        "if gpu_info.find(\"failed\") >= 0:\n",
        "    print(\"Not connected to a GPU\")\n",
        "else:\n",
        "    print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgDJVeR_qLrv"
      },
      "source": [
        "!pip install pytorch-lightning "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKVWe4qfs2zH"
      },
      "source": [
        "## Lightning Modules \n",
        "\n",
        "A `LightningModule` organizes your PyTorch code into 5 sections\n",
        "+ Computations (`init`)\n",
        "+ Train loop (`training_step`)\n",
        "+ Validation loop (`validation_step`)\n",
        "+ Test loop (`test_step`)\n",
        "+ Optimizers (`configure_optimizers`)\n",
        "\n",
        "See [the official tutorial](https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fp1tYjPpxJP"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "class LitAutoEncoder(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "                nn.Linear(28 * 28, 64),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(64, 3))\n",
        "        self.decoder = nn.Sequential(\n",
        "                nn.Linear(3, 64),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(64, 28 * 28))\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedding = self.encoder(x)\n",
        "        return embedding\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "        return optimizer\n",
        "\n",
        "    def training_step(self, train_batch, batch_idx):\n",
        "        x, y = train_batch\n",
        "        x = x.view(x.size(0), -1) #  (B, 28*28)\n",
        "        z = self.encoder(x)    \n",
        "        x_hat = self.decoder(z)\n",
        "        loss = F.mse_loss(x_hat, x)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, val_batch, batch_idx):\n",
        "        x, y = val_batch\n",
        "        x = x.view(x.size(0), -1)  # (B, 28*28)\n",
        "        z = self.encoder(x)\n",
        "        x_hat = self.decoder(z)\n",
        "        loss = F.mse_loss(x_hat, x)\n",
        "        self.log('val_loss', loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81cnV-Hir6hE"
      },
      "source": [
        "## Run experiments with `Trainer`\n",
        "\n",
        "PyTorch Lightning offers a highly customizable `Trainer`.\n",
        "\n",
        "[The official tutorial videos](https://www.pytorchlightning.ai/tutorials\n",
        ") explain trainer features. It will be 30 minutes in total. Highly recommended. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlB8d29RvH8a"
      },
      "source": [
        "# Launch tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7gzl-XWp4rE"
      },
      "source": [
        "# data\n",
        "dataset = MNIST('', train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist_train, mnist_val = random_split(dataset, [55000, 5000])\n",
        "\n",
        "train_loader = DataLoader(mnist_train, batch_size=32)\n",
        "val_loader = DataLoader(mnist_val, batch_size=32)\n",
        "\n",
        "# model\n",
        "model = LitAutoEncoder()\n",
        "\n",
        "# early stopping\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=3,\n",
        "    strict=False,\n",
        "    verbose=False,\n",
        "    mode=\"min\")\n",
        "\n",
        "# TensorBoard Logger\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "logger = TensorBoardLogger(\"logs\", name=\"ae_mnist\")\n",
        "\n",
        "# training\n",
        "trainer = pl.Trainer(callbacks=[early_stopping],\n",
        "                     max_epochs=50,\n",
        "                     auto_scale_batch_size=True,\n",
        "                     auto_lr_find=True,\n",
        "                     gpus=1,\n",
        "                     precision=16,\n",
        "                     limit_train_batches=0.5,\n",
        "                     logger=logger)\n",
        "\n",
        "trainer.fit(model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}