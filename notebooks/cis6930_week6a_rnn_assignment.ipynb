{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cis6930-week6a-rnn-assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tydRDo6t2bjd"
      },
      "source": [
        "# CIS6930 Week 6a: Recurrent Neural Networks Assignment Template\n",
        "\n",
        "---\n",
        "\n",
        "Preparation: Go to `Runtime > Change runtime type` and choose `GPU` for the hardware accelerator.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MMZ5mxJ2iUy"
      },
      "source": [
        "gpu_info = !nvidia-smi -L\n",
        "gpu_info = \"\\n\".join(gpu_info)\n",
        "if gpu_info.find(\"failed\") >= 0:\n",
        "    print(\"Not connected to a GPU\")\n",
        "else:\n",
        "    print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbAny3QK2j6B"
      },
      "source": [
        "## Preparation\n",
        "\n",
        "For this assignment, we use Hugging Face's `datasets` library, which offers a simple interface to download a wide variety of NLP datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qK5hsVkyVF_"
      },
      "source": [
        "!pip install datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C6McCfMyc3k"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# https://huggingface.co/datasets/conll2003\n",
        "train_dataset = load_dataset(\"conll2003\", split=\"train\")\n",
        "valid_dataset = load_dataset(\"conll2003\", split=\"validation\")\n",
        "test_dataset = load_dataset(\"conll2003\", split=\"test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiXG4zsw2wqz"
      },
      "source": [
        "Each dataset object follows the data format below. For the assignment, you will only use `ner_tags` and `tokens`.\n",
        "\n",
        "```\n",
        ">>> train_dataset[0]\n",
        "\n",
        "{'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
        " 'id': '0',\n",
        " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0],\n",
        " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
        " 'tokens': ['EU',\n",
        "  'rejects',\n",
        "  'German',\n",
        "  'call',\n",
        "  'to',\n",
        "  'boycott',\n",
        "  'British',\n",
        "  'lamb',\n",
        "  '.']}\n",
        "```\n",
        "\n",
        "Here is the information about `ner_tags`. For more details, see https://huggingface.co/datasets/conll2003.\n",
        "\n",
        "`ner_tags`: a list of classification labels, with possible values including O (0), B-PER (1), I-PER (2), B-ORG (3), I-ORG (4) B-LOC (5), I-LOC (6) B-MISC (7), I-MISC (8).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oab7njpn0c5q"
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeW5ViZL3r-C"
      },
      "source": [
        "### Problem 1: Create a vocabulary\n",
        "\n",
        "As shown above, sentences in the dataset are already tokenized. Since token IDs are not assigned yet, the dataset is not \"Neural Network\" ready.\n",
        "\n",
        "**Problem 1**: Create a vocabulary and conver tokens into token IDs.\n",
        "\n",
        "**Instructions/Hints:**\n",
        "- Construct a vocabulary using `train_dataset`.\n",
        "- Make sure to reserve ID for unknown tokens. \n",
        "- The vocabuary can be just a `dict` object.\n",
        "- Apply the constructed vocabulary to train/validation/test datasets and make `token_ids` fields.\n",
        "- Use `dataset.map` for the token ID conversion.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqKl7K160VWS"
      },
      "source": [
        "# https://huggingface.co/docs/datasets/processing.html\n",
        "def assign_tokenid(example):\n",
        "    \"\"\"This is example code that does NOT assign real token IDs.\n",
        "    You need to revise the code\"\"\"\n",
        "    example[\"token_ids\"] = [999999 for token in example[\"tokens\"]]\n",
        "    return example\n",
        "\n",
        "train_dataset = train_dataset.map(assign_tokenid)\n",
        "valid_dataset = valid_dataset.map(assign_tokenid)\n",
        "test_dataset = test_dataset.map(assign_tokenid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbTyjewL6HrS"
      },
      "source": [
        "# Now processed dataset contains `token_ids` field\n",
        "train_dataset[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ggpi6vI8AAR"
      },
      "source": [
        "# Select field(s) to use and specify the data type (i.e., PyTorch)\n",
        "train_dataset.set_format(type=\"torch\", columns=[\"token_ids\", \"ner_tags\"])\n",
        "valid_dataset.set_format(type=\"torch\", columns=[\"token_ids\", \"ner_tags\"])\n",
        "test_dataset.set_format(type=\"torch\", columns=[\"token_ids\", \"ner_tags\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDcsIvde8K75"
      },
      "source": [
        "# The command above overwrites the dataset object and now you should only see filtered fields\n",
        "train_dataset[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abj60DYwAWvc"
      },
      "source": [
        "## Problem 2: Implement collate function\n",
        "\n",
        "Following the example for the RNN classification code, complete collate function so that you can appropriately padding sequences for batch sampling.\n",
        "\n",
        "**Problem 2**: Complete `collate_func()`.\n",
        "\n",
        "**Instructions/Hints:**\n",
        "- `collate_func()` takes a batch and returns a batch.\n",
        "- Use `torch.nn.utils.rnn.pad_sequence` for padding.\n",
        "- Hint: insert `import pdb; pdb.set_trace()` to check the data structure. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0fk1GAGygM8"
      },
      "source": [
        "def collate_func(batch):\n",
        "    ## !!Complete code!! ##\n",
        "    pass\n",
        "    return batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOGqRZAJBI-5"
      },
      "source": [
        "Now, you should be able to load each of the dataset objects using `DataLoader` to make the datasets PyTorch-training ready."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US7c1MBEAVkY"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "dl_train = DataLoader(train_dataset,\n",
        "                      batch_size=8,\n",
        "                      collate_fn=collate_func)\n",
        "batch = next(iter(dl_train))\n",
        "print(batch[\"token_ids\"])\n",
        "print(batch[\"ner_tags\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odkwgQ06CPHW"
      },
      "source": [
        "## Problem 3: Design a BiLSTM model for NER\n",
        "\n",
        "**Problem 3**: Implement `BiLSTMForNER` class.\n",
        "\n",
        "**Instructions/Hints**:\n",
        "- For the design choise, use Bidirectional LSTM.\n",
        "- Consider refactor `SimpleRNN` in [Hands-on session Colab](https://colab.research.google.com/drive/1DZN-Bo2HBnPQPm4jrQzEIchhHdN682qP?usp=sharing)\n",
        "- Hint: The `SimpleRNN` class takes *only the last hidden state* for classification. For NER, the model has to output prediction for each token. *What do you need to change?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrWV1rybD7Qv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bso6OMYsBSKU"
      },
      "source": [
        "## Problem 4: Write a training script. \n",
        "\n",
        "**Problem 4**: Implement a `train()` function and run the script using the model and datasets. \n",
        "\n",
        "**Instructions/Hints**:\n",
        "- Evaluate training/validation loss and accuracy.\n",
        "- You can reuse `train()` in [Hands-on session Colab](https://colab.research.google.com/drive/1DZN-Bo2HBnPQPm4jrQzEIchhHdN682qP?usp=sharing), but you do need modification.\n",
        "- Hint: Now, you have to consider multiple predictions for each sequence, which is different from the classification task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTuBHurcD5xT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdmKm3CCDCHB"
      },
      "source": [
        "## Problem 5: Run the training script and summarize the results\n",
        "\n",
        "**Problem 5**: Run the training script and report the numbers. \n",
        "\n",
        "**Instructions/Hints**:\n",
        "- Add a discussion on the results. \n",
        "- [Optional] Update the `BiLSTM` class that you implemented above to take hyperparameters regarding the network architecture (e.g., `LSTM` or `GRU`, `bidirectional` or not, `stacked` or not etc.), so you can conduct comparative experiments.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CQOVZiRD6XR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}