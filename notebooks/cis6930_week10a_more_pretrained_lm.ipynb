{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cis6930-week10a-more-pretrained-lm.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tydRDo6t2bjd"
      },
      "source": [
        "# CIS6930 Week 10a More Pre-trained Language Models Hands-on Session\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "Preparation: Go to `Runtime > Change runtime type` and choose `GPU` for the hardware accelerator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MMZ5mxJ2iUy"
      },
      "source": [
        "gpu_info = !nvidia-smi -L\n",
        "gpu_info = \"\\n\".join(gpu_info)\n",
        "if gpu_info.find(\"failed\") >= 0:\n",
        "    print(\"Not connected to a GPU\")\n",
        "else:\n",
        "    print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbAny3QK2j6B"
      },
      "source": [
        "## Preparation\n",
        "\n",
        "For this notebookt, we use Hugging Face's `transformers` library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qK5hsVkyVF_"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAA5kQ6479xA"
      },
      "source": [
        "## Recap: Basic Patterns\n",
        "\n",
        "\n",
        "- Remember the library has two patterns\n",
        "- See also [the Quick Tour](https://huggingface.co/transformers/quicktour.html#quick-tour)\n",
        "\n",
        "\n",
        "#### A) The \"`tokenizer` + `model`\" pattern \n",
        "\n",
        "```\n",
        ">>> from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        ">>> model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        ">>> pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        ">>> tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "```\n",
        "\n",
        "#### B) The \"`pipeline`\" pattern\n",
        "\n",
        "```\n",
        ">>> from transformers import pipeline\n",
        ">>> classifier = pipeline('sentiment-analysis')\n",
        ">>> classifier('We are very happy to show you the ðŸ¤— Transformers library.')\n",
        "```\n",
        "\n",
        "For `pipeline`, see also [Pipelines documentation](https://huggingface.co/transformers/main_classes/pipelines.html) for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrRvDO5KbeRo"
      },
      "source": [
        "## Playing with GPT-2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiNJFvyfaZf3"
      },
      "source": [
        "from transformers import pipeline, set_seed\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"gpt2\", device=0)\n",
        "set_seed(42)\n",
        "generator(\"Hello, I'm a language model,\",\n",
        "          max_length=30,\n",
        "          num_return_sequences=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sjqq5J-1a3la"
      },
      "source": [
        "# Change the input text and other hyper-parameters\n",
        "generator(\"Deep Learning is a great but\",\n",
        "          max_length=50,\n",
        "          num_return_sequences=5,\n",
        "          num_beams=5, \n",
        "          no_repeat_ngram_size=2, \n",
        "          early_stopping=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjNBEF2fjnR1"
      },
      "source": [
        "# Change the input text and other hyper-parameters\n",
        "generator(\"Deep Learning is a great but\",\n",
        "          max_length=50,\n",
        "          num_return_sequences=5,\n",
        "          do_sample=True,\n",
        "          topk=3,\n",
        "          no_repeat_ngram_size=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC-oBm-aj2Tx"
      },
      "source": [
        "# Change the input text and other hyper-parameters\n",
        "generator(\"Deep Learning is a great but\",\n",
        "          max_length=50,\n",
        "          num_return_sequences=5,\n",
        "          do_sample=True,\n",
        "          topp=0.95,   # <= Change this value and see what happens\n",
        "          no_repeat_ngram_size=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7fmDcbib0cs"
      },
      "source": [
        "## Playing with T5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9QBpUtAsE6a"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
        "\n",
        "input_ids = tokenizer(\"translate English to German: The house is wonderful.\",\n",
        "                      return_tensors='pt').input_ids\n",
        "labels = tokenizer(\"Das Haus ist wunderbar.\", return_tensors=\"pt\").input_ids\n",
        "\n",
        "# the forward function automatically creates the correct decoder_input_ids\n",
        "outputs = model(input_ids=input_ids, labels=labels)\n",
        "outputs.loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cehhXtZLstHw"
      },
      "source": [
        "input_ids = tokenizer(\"translate English to German: The house is wonderful.\",\n",
        "                      return_tensors=\"pt\").input_ids\n",
        "outputs = model.generate(input_ids)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxKsY7VyxOls"
      },
      "source": [
        "## See Also\n",
        "\n",
        "- Go to [Model Hub](https://huggingface.co/models)\n",
        "- Be mindful \n",
        "    - (1) whether the model is just pre-trained or also fine-tuned\n",
        "    - (2) if it is the official or a third-party model"
      ]
    }
  ]
}