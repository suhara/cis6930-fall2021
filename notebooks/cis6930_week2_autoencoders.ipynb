{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cis6930-week2-autoencoders.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRgpqL0KVO43"
      },
      "source": [
        "# CIS6930 Week 2: Autoencoders\n",
        "\n",
        "---\n",
        "\n",
        "Preparation: Go to `Runtime > Change runtime type` and choose `GPU` for the hardware accelerator.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WNf7qUvYDCeD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1dpc5PwIghS"
      },
      "source": [
        "## A magic command to check your assigned GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uayE3ioc3k_h"
      },
      "source": [
        "gpu_info = !nvidia-smi -L\n",
        "gpu_info = \"\\n\".join(gpu_info)\n",
        "if gpu_info.find(\"failed\") >= 0:\n",
        "  print(\"Not connected to a GPU\")\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Jpe1bw6ImPn"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7h-6LpjVDHW"
      },
      "source": [
        "import copy\n",
        "import random\n",
        "from time import time\n",
        "from typing import Any, Dict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZLilYXAI7Cr"
      },
      "source": [
        "## MNIST dataset from Torchvision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9sBXgBsV6dI"
      },
      "source": [
        "import torchvision\n",
        "\n",
        "train_dataset = torchvision.datasets.MNIST(\"./data\", train=True, download=True,\n",
        "                                            transform=torchvision.transforms.Compose(\n",
        "                                                [torchvision.transforms.ToTensor(),\n",
        "                                                 # For standardization: 0.1307 (mean), 0.3081 (var)\n",
        "                                                 torchvision.transforms.Normalize((0.1307,), (0.3081,))]))\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(train_dataset, [50000, 10000],\n",
        "                                                             generator=torch.Generator().manual_seed(5))\n",
        "test_dataset = torchvision.datasets.MNIST(\"/data\", train=False, download=True,\n",
        "                                           transform=torchvision.transforms.Compose(\n",
        "                                               [torchvision.transforms.ToTensor(),\n",
        "                                                torchvision.transforms.Normalize((0.1307,), (0.3081,))]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcnUXJ-uWC5f"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.imshow(train_dataset[0][0].squeeze(0), cmap=\"gray\", interpolation=\"none\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-stPdW6xs-nl"
      },
      "source": [
        "train_dataset[0][0].view(-1).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-_kIWnkdbxO"
      },
      "source": [
        "## Training framework\n",
        "\n",
        "It must have been cumbersome to copy and paste the training code to run experiments with different configurations. \n",
        "\n",
        "TBD in a little bit more organized manner. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tjf9SlQi5DeA"
      },
      "source": [
        "def train(model: nn.Module,\n",
        "              train_dataset: Dataset,\n",
        "              valid_dataset: Dataset,\n",
        "              config: Dict[str, Any],\n",
        "              random_seed: int = 0):\n",
        "  \n",
        "    # Random Seeds ===============\n",
        "    torch.manual_seed(random_seed)\n",
        "    random.seed(random_seed)\n",
        "    np.random.seed(random_seed)\n",
        "    # Random Seeds ===============\n",
        "\n",
        "    # GPU configuration\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    #device = torch.device(\"tpu\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    dl_train = DataLoader(train_dataset,\n",
        "                          batch_size=config[\"batch_size\"])\n",
        "    dl_valid = DataLoader(valid_dataset)\n",
        "                  \n",
        "    # Model, Optimzier, Loss function\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = config[\"optimizer_cls\"](model.parameters(), lr=config[\"lr\"])\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    # For each epoch\n",
        "    eval_list = []\n",
        "    t0 = time()\n",
        "    best_val = None\n",
        "    best_model = None\n",
        "    for n in range(config[\"n_epochs\"]):\n",
        "        t1 = time()\n",
        "        print(\"Epoch {}\".format(n))\n",
        "        # Training\n",
        "        train_loss = 0.\n",
        "        train_pred_list = []\n",
        "        train_true_list = []\n",
        "        model.train()  # Switch to the training mode\n",
        "\n",
        "        # For each batch\n",
        "        for batch in dl_train:\n",
        "            optimizer.zero_grad()              # Initialize gradient information\n",
        "            X, y = batch\n",
        "            X = X.view(X.size(0), -1).to(device) # (batch_size, 1, 28, 28) -> (batch_size, 768)\n",
        "            out = model(X)                     # Call `forward()` function of the model\n",
        "            loss = loss_fn(out, X)             # Calculate loss \n",
        "            loss.backward()                    # Backpropagate the loss value\n",
        "            optimizer.step()                   # Update the parameters\n",
        "            train_loss += loss.data.item() * config[\"batch_size\"]\n",
        "\n",
        "        train_loss /= (len(dl_train) * config[\"batch_size\"])\n",
        "        print(\"    Training loss: {:.4f}\".format(train_loss))\n",
        "\n",
        "        # Validation\n",
        "        valid_loss = 0.\n",
        "        valid_pred_list = []\n",
        "        valid_true_list = []\n",
        "\n",
        "        model.eval()  # Switch to the evaluation mode\n",
        "        for i, batch in enumerate(dl_valid):\n",
        "            X, y = batch\n",
        "            X = X.view(X.size(0), -1).to(device) # (batch_size, 1, 28, 28) -> (batch_size, 768)\n",
        "            out = model(X)\n",
        "            loss = loss_fn(out, X.to(device))\n",
        "            valid_loss += loss.data.item()\n",
        "\n",
        "        valid_loss /= len(dl_valid)\n",
        "        print(\"  Validation loss: {:.4f}\".format(valid_loss))\n",
        "\n",
        "        # Model selection\n",
        "        if best_val is None or valid_loss < best_val:\n",
        "            best_model = copy.deepcopy(model)\n",
        "            best_val = valid_loss\n",
        "\n",
        "        # Orig/generated image pair\n",
        "        x_pair = torch.cat([X[0].reshape(28, 28), torch.zeros(28, 1).to(device), model(X[0]).reshape(28, 28)], axis=1)\n",
        "        plt.imshow(x_pair.detach().cpu().numpy(),\n",
        "                  cmap=\"gray\", interpolation=\"none\")\n",
        "        plt.show()\n",
        "\n",
        "        t2 = time()\n",
        "        print(\"     Elapsed time: {:.1f} [sec]\".format(t2 - t1))\n",
        "\n",
        "        # Store train/validation loss values\n",
        "        eval_list.append([n, train_loss, valid_loss, t2 - t1])\n",
        "\n",
        "    eval_df = pd.DataFrame(eval_list, columns=[\"epoch\", \"train_loss\", \"valid_loss\", \"time\"])\n",
        "    eval_df.set_index(\"epoch\")\n",
        "\n",
        "    print(\"Total time: {:.1f} [sec]\".format(t2 - t0))\n",
        "\n",
        "    # Return the best model and trainining/validation information\n",
        "    return {\"model\": best_model,\n",
        "            \"best_val\": best_val,\n",
        "            \"eval_df\": eval_df}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdMZBvboJIHm"
      },
      "source": [
        "# DO NOT EDIT THE CODE UNTIL HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0L_hTepIpvk"
      },
      "source": [
        "## Models (In-class exercise)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn5P7EweIwIo"
      },
      "source": [
        "### Exercise 1: Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld4cjWy80pj6"
      },
      "source": [
        "## Complete the code ##\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 hidden_dim: int = 64):\n",
        "        super().__init__()\n",
        "        self.encoder = nn.Sequential(nn.Linear(784, hidden_dim),\n",
        "                                     nn.ReLU())\n",
        "        self.decoder = nn.Sequential(nn.Linear(hidden_dim, 784))\n",
        "        \n",
        "    def encode(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def decode(self, x):\n",
        "        return self.decoder(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.encode(x)\n",
        "        out = self.decode(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo-wbm7LI0Cx"
      },
      "source": [
        "### Exercise 2: Denoising Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH-kSfXv7hN8"
      },
      "source": [
        "## Complete the code ##\n",
        "class DenoisingAutoEncoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 hidden_dim: int = 64,\n",
        "                 noise_factor: float = 0.01):\n",
        "        super().__init__()\n",
        "        #\n",
        "        #\n",
        "        #\n",
        "\n",
        "    def encode(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def decode(self, x):\n",
        "        return self.decoder(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.training: # True if model.train(); False if model.eval()\n",
        "            # Add noise\n",
        "            \n",
        "        # COMPLETE CODE (3-5 LINES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YikkRUN27pX6"
      },
      "source": [
        "class DenoisingAutoEncoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 hidden_dim: int = 64,\n",
        "                 noise_factor: float = 0.01):\n",
        "        super().__init__()\n",
        "        self.noise_factor = noise_factor\n",
        "        self.encoder = nn.Sequential(nn.Linear(28 * 28, hidden_dim),\n",
        "                                     nn.ReLU())\n",
        "        self.decoder = nn.Sequential(nn.Linear(hidden_dim, 28 * 28))\n",
        "        \n",
        "    def encode(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def decode(self, x):\n",
        "        return self.decoder(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.training: # True if model.train(); False if model.eval()\n",
        "           # Add random noise for training \n",
        "           x += torch.randn_like(x) * self.noise_factor\n",
        "        embedding = self.encoder(x)\n",
        "        out = self.decoder(embedding)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeCY3o1f8Clk"
      },
      "source": [
        "# torch.randn_like(torch.Tensor([1,2,3]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63J0pvJEJgwk"
      },
      "source": [
        "## Experiment: Original Image Reconstruction \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75vip-Mb6pds"
      },
      "source": [
        "# Change the learning rate and run the same experiment\n",
        "config = {\"optimizer_cls\": optim.Adam,\n",
        "          \"lr\": 0.0001,  # lr = {0.01, 0.001, 0.0001}\n",
        "          \"batch_size\": 16,\n",
        "          \"n_epochs\": 5}\n",
        "model = AutoEncoder()\n",
        "output = train(model, train_dataset, valid_dataset, config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tece4BZBOiN4"
      },
      "source": [
        "### Generating images\n",
        "\n",
        "After training, you can generate images from latent vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EcgQRylOk1v"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "plt.imshow(test_dataset[0][0].squeeze(0),\n",
        "           cmap=\"gray\",\n",
        "           interpolation=\"none\")\n",
        "plt.show()\n",
        "\n",
        "# Use the first data\n",
        "X, y = test_dataset[0]\n",
        "z = model.encode(X.view(-1).to(device))\n",
        "\n",
        "out0 = model.decode(z)\n",
        "out1 = model.decode(z + (torch.randn_like(z) * 0.1)) # Add small noise\n",
        "out2 = model.decode(z + (torch.randn_like(z) * 0.5)) # Add medium noise\n",
        "out3 = model.decode(z + (torch.randn_like(z) * 1.0)) # Add large noise\n",
        "\n",
        "plt.imshow(out0.view(28, 28).detach().cpu(),\n",
        "           cmap=\"gray\",\n",
        "           interpolation=\"none\")\n",
        "plt.show()\n",
        "plt.imshow(out1.view(28, 28).detach().cpu(),\n",
        "           cmap=\"gray\",\n",
        "           interpolation=\"none\")\n",
        "plt.show()\n",
        "plt.imshow(out2.view(28, 28).detach().cpu(),\n",
        "           cmap=\"gray\",\n",
        "           interpolation=\"none\")\n",
        "plt.show()\n",
        "plt.imshow(out3.view(28, 28).detach().cpu(),\n",
        "           cmap=\"gray\",\n",
        "           interpolation=\"none\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbiXkpCdaugc"
      },
      "source": [
        "# Generating images from random noise\n",
        "for i in range(6):\n",
        "  plt.imshow(\n",
        "      model(torch.randn_like(X.view(-1)).to(device)).detach().cpu().view(28, 28),\n",
        "      cmap=\"gray\",\n",
        "      interpolation=\"none\")\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
